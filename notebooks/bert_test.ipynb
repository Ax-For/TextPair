{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from textpair.preprocess.dummy_preprocessor import DummyPreprocessor\n",
    "from textpair.analyze.bert_analyzer import BertAnalyzer\n",
    "from textpair.vectorize.bert_vectorizer import BertVectorizer\n",
    "from textpair.model.bert_model import BertModel\n",
    "from textpair.pair_ann import PairAnn\n",
    "from textpair.semantic.base_semantic import BaseSemantic\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_FILE = '/home/aaron/model_files/bert/pytorch/bert-base-chinese.tar.gz'\n",
    "BERT_VOCAB_FILE = '/home/aaron/model_files/bert/pytorch/bert-base-chinese-vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file /home/aaron/model_files/bert/pytorch/bert-base-chinese.tar.gz\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /home/aaron/model_files/bert/pytorch/bert-base-chinese.tar.gz to temp dir /tmp/tmpcxayey2y\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file /home/aaron/model_files/bert/pytorch/bert-base-chinese-vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(BERT_MODEL_FILE)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_VOCAB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '明',\n",
       " '天',\n",
       " '天',\n",
       " '气',\n",
       " '怎',\n",
       " '么',\n",
       " '样',\n",
       " '?',\n",
       " '[SEP]',\n",
       " '明',\n",
       " '天',\n",
       " '天',\n",
       " '气',\n",
       " '如',\n",
       " '何',\n",
       " '？',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"[CLS]明天天气怎么样 ? [SEP] 明天天气如何？ [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 3209,\n",
       " 1921,\n",
       " 1921,\n",
       " 3698,\n",
       " 2582,\n",
       " 720,\n",
       " 3416,\n",
       " 136,\n",
       " 102,\n",
       " 3209,\n",
       " 1921,\n",
       " 1921,\n",
       " 3698,\n",
       " 1963,\n",
       " 862,\n",
       " 8043,\n",
       " 102]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[-1].numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tmp = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "care",
   "language": "python",
   "name": "care"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
